{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a RNN\n",
    "\n",
    "### Arquitetura:\n",
    "\n",
    "Palavra -> Embedding -> GRU -> Dense\n",
    "\n",
    "No Pytorch existe a possibilidade do desenvolvimento de RNNs com tamanhos diferentes (sem a necessiade do 0 padding) isso econimiza tempo de processamento.\n",
    "\n",
    "As etapas para o uso dessa função são as seguintes:\n",
    "    1. Pad de todoas as sequências do dataset;\n",
    "    2. Unpad dessas sequências utilizando o pack_padded_sequence;\n",
    "    3. Input na GRU;\n",
    "    4. Refaz o pad para entrar na camada de previsão utilizando o pad_packed_sequence;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from data_preparator import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "class DAC(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, n_classes):\n",
    "        super(DAC, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        #Inicializacao da rede\n",
    "        self.embedding = nn.Embedding(self.vocab_size+1, self.embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size)#, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, seq, lengths, gpu = False):\n",
    "        print(\"Sequence shape: \", seq.shape)\n",
    "        print('Lengths',lengths)\n",
    "        bs = seq.size(1)\n",
    "        print(\"Batch size: \", bs)\n",
    "        self.hidden = self._init_hidden(bs, gpu)\n",
    "        \n",
    "        embeds = self.embedding(seq)\n",
    "        embeds = pack_padded_sequence(embeds, lengths) #faz o unpad da sequencia\n",
    "        \n",
    "        gru_out, self.hidden = self.gru(embeds, self.hidden) #retorna o hidden_state de todos os timesteps\n",
    "        \n",
    "        gru_out, lenghts = pad_packed_sequence(gru_out) # faz o pad da sequencia para o tamanho maximo do batch\n",
    "        \n",
    "        print('GRU output(all timesteps)', gru_out.shape)\n",
    "        print(gru_out)\n",
    "        \n",
    "        #Como é um problema de classificacao, vou usar a ultima camada hidden\n",
    "        output = self.fc(self.hidden[-1])\n",
    "        \n",
    "        return F.log_softmax(output, dim=-1)\n",
    "    \n",
    "    def _init_hidden(self, batch_size, gpu):\n",
    "        if gpu: return Variable(torch.zeros((1,batch_size,self.hidden_size)).cuda())\n",
    "        else: return Variable(torch.zeros((1,batch_size,self.hidden_size)))\n",
    "        return self.create_variable(hidden)\n",
    "\n",
    "    def create_variable(self, tensor):\n",
    "        # Do cuda() before wrapping with variable\n",
    "        if torch.cuda.is_available():\n",
    "            return Variable(tensor.cuda())\n",
    "        else:\n",
    "            return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded, labels, vocab_size, x_lengs = prepare_dataset('./conversas_mexidas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAC(\n",
      "  (embedding): Embedding(2492, 20)\n",
      "  (gru): GRU(20, 5)\n",
      "  (fc): Linear(in_features=5, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = DAC(vocab_size, embedding_dim=20, hidden_size=5, n_classes=7)\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueDataset(Dataset):\n",
    "    def __init__(self, encoded_dialogues, labels, x_lengs):\n",
    "        self.len = encoded_dialogues.shape[0]\n",
    "        self.x_data = encoded_dialogues\n",
    "        self.y_data = torch.tensor(labels) #one-hot encoding\n",
    "        self.x_lengs = x_lengs\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        xb = self.x_data[index]\n",
    "        yb = self.y_data[index]\n",
    "        lens = self.x_lengs[index]\n",
    "        return xb, yb, lens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_batch(x, y, lenghts):\n",
    "    lengths,indx = lenghts.sort(dim = 0, descending = True)\n",
    "    x = x[indx]\n",
    "    y = y[indx]\n",
    "    \n",
    "    return x.transpose(0,1), y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DialogueDataset(padded, labels, x_lengs)\n",
    "train_loader = DataLoader(dataset= dataset,\n",
    "                         batch_size = 2,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, l = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys, ls = sort_batch(x, y, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape:  torch.Size([90, 2])\n",
      "Lengths tensor([19, 13])\n",
      "Batch size:  2\n",
      "GRU output(all timesteps) torch.Size([19, 2, 5])\n",
      "tensor([[[ 0.4509,  0.0404,  0.0292, -0.2293, -0.5114],\n",
      "         [ 0.5787, -0.0287, -0.6487,  0.0546,  0.0541]],\n",
      "\n",
      "        [[ 0.3351,  0.4517,  0.0061, -0.3870, -0.7261],\n",
      "         [ 0.4655, -0.0259,  0.0458, -0.0820, -0.1191]],\n",
      "\n",
      "        [[ 0.2292,  0.7219,  0.1385, -0.0720, -0.6182],\n",
      "         [ 0.2406,  0.5915,  0.2133, -0.2711, -0.3446]],\n",
      "\n",
      "        [[ 0.3389,  0.0819,  0.3405, -0.2735, -0.4635],\n",
      "         [ 0.1298,  0.4775, -0.2844,  0.1993, -0.2503]],\n",
      "\n",
      "        [[ 0.0436,  0.0637, -0.2007,  0.0418, -0.7701],\n",
      "         [ 0.0092, -0.1366,  0.1250,  0.1425, -0.2221]],\n",
      "\n",
      "        [[ 0.3242, -0.2187,  0.1645, -0.4265, -0.3611],\n",
      "         [-0.1392, -0.4530, -0.8354,  0.0431,  0.0124]],\n",
      "\n",
      "        [[-0.1454, -0.4246, -0.6825, -0.3004, -0.3033],\n",
      "         [-0.0116, -0.4997, -0.6354, -0.3558,  0.3546]],\n",
      "\n",
      "        [[-0.3668, -0.7073, -0.6144, -0.2329,  0.0695],\n",
      "         [-0.1740, -0.5519, -0.6816, -0.4273,  0.4345]],\n",
      "\n",
      "        [[-0.6811, -0.8419, -0.8442,  0.1562,  0.0901],\n",
      "         [-0.2595,  0.1869,  0.2576, -0.4522,  0.5185]],\n",
      "\n",
      "        [[ 0.3673, -0.7927, -0.5557,  0.3732,  0.1120],\n",
      "         [-0.1660,  0.1008,  0.1987, -0.6656,  0.7285]],\n",
      "\n",
      "        [[ 0.8150, -0.8286, -0.2104,  0.5313,  0.0860],\n",
      "         [-0.1784,  0.1816,  0.1800, -0.4792,  0.7375]],\n",
      "\n",
      "        [[ 0.0965,  0.1992, -0.4771,  0.7323, -0.5222],\n",
      "         [-0.2225, -0.2428, -0.8479, -0.2195,  0.7432]],\n",
      "\n",
      "        [[-0.0784,  0.0787, -0.0974, -0.2765, -0.1335],\n",
      "         [-0.2619, -0.3517,  0.0134,  0.0492,  0.7894]],\n",
      "\n",
      "        [[-0.2615, -0.0009, -0.3831, -0.2117,  0.4431],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.1058,  0.5417, -0.5313,  0.1783,  0.1931],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.1519, -0.1413, -0.7002, -0.0545, -0.2280],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0501, -0.5237, -0.6914, -0.3765, -0.0020],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2205, -0.3002,  0.1040, -0.2933,  0.1986],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2280, -0.0065,  0.0011, -0.4617,  0.3835],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "outp = m(xs, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SÃO AS PROBABILIDADES DE CADA CLASSE \n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.], grad_fn=<MaxBackward0>), tensor([0, 0]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(outp, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n, top_i = outp.topk(1) #PEGA AS CLASSES COM MAIOR PROBABILIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape:  torch.Size([90, 2])\n",
      "Lengths tensor([19, 13])\n",
      "Batch size:  2\n",
      "GRU output(all timesteps) torch.Size([19, 2, 30])\n",
      "tensor([[[ 0.0308, -0.4410, -0.3945,  ...,  0.0897,  0.2613,  0.1475],\n",
      "         [ 0.0017,  0.2206,  0.2220,  ...,  0.2697,  0.2443, -0.2768]],\n",
      "\n",
      "        [[ 0.2025, -0.5089, -0.0540,  ...,  0.3787,  0.3920, -0.2531],\n",
      "         [-0.4570, -0.0696,  0.2631,  ...,  0.2554,  0.5169,  0.3255]],\n",
      "\n",
      "        [[ 0.3371, -0.3685,  0.3557,  ..., -0.1337,  0.0140,  0.1656],\n",
      "         [-0.3873, -0.1054,  0.1323,  ...,  0.4335,  0.3956, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0275,  0.3332, -0.1860,  ..., -0.0986, -0.3066,  0.2082],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0376,  0.2151,  0.3490,  ..., -0.0691,  0.2346,  0.4970],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.4271,  0.2970,  0.0215,  ..., -0.0913, -0.0317,  0.5241],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-108fd67c9fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenghts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/esquizo/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:21"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "loss_fn =  F.nll_loss\n",
    "model = DAC(vocab_size, embedding_dim=20, hidden_size=30, n_classes=7)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    y_true_train = list()\n",
    "    y_pred_train = list()\n",
    "    total_loss_train = 0\n",
    "    \n",
    "    for x, y, lengths in iter(train_loader):\n",
    "        x, y , lenghts = sort_batch(x,y,lengths)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        pred = model(x, lenghts)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7884, -1.6513, -1.9986, -2.0209, -2.0312, -2.1240, -2.1024],\n",
       "        [-1.8666, -2.0058, -2.1559, -1.9408, -1.8920, -2.0552, -1.7569]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
